{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDM architecture \n",
    "\n",
    "### Step 1: Load the image dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import gc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag to run on GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_on_gpu = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No of frames the model will process at a time. For CPU 128 frames work if you have GPU with 12 GB VRAM it will eat up all memory. I tested it with 32 frames and that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No of frame we will process at a time\n",
    "no_of_frames = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if run_on_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the images from the data. \n",
    "First getting the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path = 'data'\n",
    "data_dir = os.path.abspath(relative_path)\n",
    "\n",
    "# This below code is only for Anirudha's PC because after restarting Python kernel the abspath gets a bit messed up\n",
    "data_dir = 'C:\\\\Users\\\\aniru\\\\Desktop\\\\Code\\\\VPTAirsim\\\\data'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the filenames by the number in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_from_string(string):\n",
    "    # Extracts the number from a string by filtering out non-digit characters\n",
    "    return int(''.join(filter(str.isdigit, string)))\n",
    "\n",
    "def sort_array_by_number(array):\n",
    "    # Sorts the array based on the number appearing in each string\n",
    "    return sorted(array, key=get_number_from_string)\n",
    "\n",
    "sorted_filenames = sort_array_by_number(filenames)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for name in sorted_filenames:\n",
    "    \n",
    "    if \"w\" in name:\n",
    "        labels.append(0)\n",
    "    elif \"a\" in name:\n",
    "        labels.append(1)\n",
    "    elif \"s\" in name:\n",
    "        labels.append(2)\n",
    "    elif \"d\" in name:\n",
    "        labels.append(3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making one hot label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "one_hot_labels = torch.eye(4)[labels]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using the filenames to load images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the total data is a multiplication of no of frames \n",
    "dataset_size = len(sorted_filenames) - (len(sorted_filenames) % no_of_frames)\n",
    "\n",
    "dataset = torch.zeros(dataset_size, 3, 128, 128)\n",
    "for i in range(dataset_size):\n",
    " dataset[i] = torchvision.io.read_image(os.path.join(data_dir, sorted_filenames[i]))\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the pixel value by dividing it by 255. Now it is between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.size())\n",
    "dataset = dataset / 255.0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to make no_of_frames size chunks of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset with data and their label\n",
    "data = TensorDataset(dataset, one_hot_labels)\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(data, batch_size=no_of_frames, shuffle=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Pass the data through 3D Convolution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a final model. I am writing this to make proper data shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temporal3DConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Temporal3DConv, self).__init__()\n",
    "\n",
    "        # 3 is input channel because of RGB images. \n",
    "        # 128 is the output channel or learnable filters\n",
    "        # Kernel size 5 is temporal kernel width \n",
    "        # (1*1) is spatial kernel width\n",
    "        # 2 Depth padding for initial and end frames\n",
    "        self.conv3d = nn.Conv3d(3, 128, kernel_size=(5, 1, 1), padding=(2,0,0))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv3d(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Pass the 3D Convolution layer outcome through ResNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the middle Res Net layer. So the ResNetBlock represents the Deep residual learning for image\n",
    "recognition paper architecture. \n",
    "\n",
    "ResNetBlocksWithPooling represents the Resnet stack mentioned in the VPT paper. We will use three stacks consecuvely then flatten it before passing it to attention layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNetBlocksWithPooling(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlocksWithPooling, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.resnet_block1 = ResNetBlock(out_channels, out_channels)\n",
    "        self.resnet_block2 = ResNetBlock(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.pool(out)\n",
    "        out = self.resnet_block1(out)\n",
    "        out = self.resnet_block2(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Pass ResNet outcome through Multiheaded Residual Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FrameWiseDense(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(FrameWiseDense, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResidualTransformerBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, dropout=0.1):\n",
    "        super(ResidualTransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embedding_dim, num_heads, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(embedding_dim)\n",
    "        self.dense1 = FrameWiseDense(embedding_dim, 16384)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(embedding_dim)\n",
    "        self.dense2 = FrameWiseDense(16384, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out, _ = self.attention(x, x, x)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.norm1(out + residual)\n",
    "        residual = out\n",
    "        out = self.dense1(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.dense2(out)\n",
    "        out = self.norm2(out + residual)\n",
    "        return out\n",
    "\n",
    "class ActionPredictionModel(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super(ActionPredictionModel, self).__init__()\n",
    "        # the initial value is 16384 because it is the flattened output dimension for ResNet\n",
    "        self.dense1 = FrameWiseDense(16384, 256)\n",
    "        self.dense2 = FrameWiseDense(256, 4096)\n",
    "        self.residual_transformer_blocks = nn.Sequential(\n",
    "            ResidualTransformerBlock(embedding_dim=4096, num_heads=32),\n",
    "            ResidualTransformerBlock(embedding_dim=4096, num_heads=32),\n",
    "            ResidualTransformerBlock(embedding_dim=4096, num_heads=32),\n",
    "            ResidualTransformerBlock(embedding_dim=4096, num_heads=32)\n",
    "        )\n",
    "        self.dense3 = FrameWiseDense(4096, 16384)\n",
    "        self.dense4 = FrameWiseDense(16384, 4096)\n",
    "        self.action_head = nn.Linear(4096, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dense1(x)\n",
    "        out = self.dense2(out)\n",
    "        # out = out.permute(1, 0, 2)\n",
    "        out = self.residual_transformer_blocks(out)\n",
    "        # out = out.permute(1, 0, 2)\n",
    "        out = self.dense3(out)\n",
    "        out = self.dense4(out)\n",
    "        # out = out.mean(dim=1)\n",
    "        out = self.action_head(out)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Combining everything in a single model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IDM, self).__init__()\n",
    "        self.temporal3DConv = Temporal3DConv()\n",
    "        self.ResNetStack1 = ResNetBlocksWithPooling(128, 64)\n",
    "        self.ResNetStack2 = ResNetBlocksWithPooling(64, 64)\n",
    "        self.ResNetStack3 = ResNetBlocksWithPooling(64, 64)\n",
    "        self.flattenLayer = nn.Flatten()\n",
    "        self.transformerLayer = ActionPredictionModel(num_actions=4)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # For Conv3D the input format is (batch_size, num_channels, num_frames, height, width)\n",
    "        # So I am using unsqueeze to increase the outer dimension to make batch_size = 1 . \n",
    "        # Then using the permute to make the dimension in proper shape.\n",
    "        out = input.unsqueeze(0).permute(0, 2, 1, 3, 4)\n",
    "        out = self.temporal3DConv(out)\n",
    "        \n",
    "        # To match the expected input shape of the ResNet model, we need to reshape the output tensor. \n",
    "        # First, we use permute to rearrange the dimensions of the tensor, swapping the second and third dimensions. \n",
    "        # Then, we use contiguous to ensure the tensor's memory is laid out contiguously. \n",
    "        # Finally, we use view to reshape the tensor into a 4D tensor with dimensions (batch_size * num_frames, num_channels, height, width).\n",
    "\n",
    "        out = out.permute(0, 2, 1, 3, 4).contiguous().view(1 * no_of_frames, 128, 128, 128)\n",
    "        out = self.ResNetStack1(out)\n",
    "        out = self.ResNetStack2(out)\n",
    "        out = self.ResNetStack3(out)\n",
    "        out = self.flattenLayer(out)\n",
    "        out = self.transformerLayer(out)\n",
    "        return out\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some codes to check GPU memory status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.mem_get_info())\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.mem_get_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 Declaring the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and printing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDM(\n",
      "  (temporal3DConv): Temporal3DConv(\n",
      "    (conv3d): Conv3d(3, 128, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0))\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (ResNetStack1): ResNetBlocksWithPooling(\n",
      "    (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (resnet_block1): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (resnet_block2): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (ResNetStack2): ResNetBlocksWithPooling(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (resnet_block1): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (resnet_block2): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (ResNetStack3): ResNetBlocksWithPooling(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (resnet_block1): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (resnet_block2): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (flattenLayer): Flatten(start_dim=1, end_dim=-1)\n",
      "  (transformerLayer): ActionPredictionModel(\n",
      "    (dense1): FrameWiseDense(\n",
      "      (linear): Linear(in_features=16384, out_features=256, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (dense2): FrameWiseDense(\n",
      "      (linear): Linear(in_features=256, out_features=4096, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (residual_transformer_blocks): Sequential(\n",
      "      (0): ResidualTransformerBlock(\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=4096, out_features=4096, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (dense1): FrameWiseDense(\n",
      "          (linear): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (dense2): FrameWiseDense(\n",
      "          (linear): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): ResidualTransformerBlock(\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=4096, out_features=4096, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (dense1): FrameWiseDense(\n",
      "          (linear): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (dense2): FrameWiseDense(\n",
      "          (linear): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): ResidualTransformerBlock(\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=4096, out_features=4096, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (dense1): FrameWiseDense(\n",
      "          (linear): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (dense2): FrameWiseDense(\n",
      "          (linear): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (3): ResidualTransformerBlock(\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=4096, out_features=4096, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (dense1): FrameWiseDense(\n",
      "          (linear): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (dense2): FrameWiseDense(\n",
      "          (linear): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dense3): FrameWiseDense(\n",
      "      (linear): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (dense4): FrameWiseDense(\n",
      "      (linear): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (action_head): Linear(in_features=4096, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = IDM().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkinng number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Parameters: 945614020\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Trainable Parameters: {total_params}\")\n",
    "print(next(model.parameters()).is_cuda)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 Doing Forward pass (NEED TO MODIFY TO SUPPORT FULL TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 4])\n",
      "torch.Size([128, 4])\n"
     ]
    }
   ],
   "source": [
    "output = any\n",
    "\n",
    "for framechunk in dataloader:\n",
    "    # Access the batched tensor data\n",
    "    # Pass the input through the model\n",
    "    input = framechunk[0].to(device)\n",
    "    true_label = framechunk[1].to(device)\n",
    "    output = model(input)\n",
    "    del input\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(output.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This theoritically should clear up the memory but this is not working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
