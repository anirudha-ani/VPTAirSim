{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to make an IDM architecture \n",
    "\n",
    "### Step 1: Load the image dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the images from the data. \n",
    "First getting the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'c:\\\\Users\\\\aniru\\\\Desktop\\\\Code\\\\VPTAirSim\\\\data'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']\n",
    "\n",
    "dataset_size = len(filenames)\n",
    "dataset = torch.zeros(dataset_size - 4, 15, 128, 128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using the filenames to load images.\n",
    "\n",
    "Here evey image is concatinated with 2 images before it and 2 images after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dataset_size-4):\n",
    " t_minus_2 = torchvision.io.read_image(os.path.join(data_dir, filenames[i]))\n",
    " t_minus_1 = torchvision.io.read_image(os.path.join(data_dir, filenames[i+1]))\n",
    " t = torchvision.io.read_image(os.path.join(data_dir, filenames[i+2]))\n",
    " t_plus_1 = torchvision.io.read_image(os.path.join(data_dir, filenames[i+3]))\n",
    " t_plus_2 = torchvision.io.read_image(os.path.join(data_dir, filenames[i+4]))\n",
    "\n",
    " dataset[i] = torch.cat((t_minus_2, t_minus_1, t ,t_plus_1, t_plus_2))\n",
    " \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the pixel value by dividing it by 255. Now it is between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.size()\n",
    "dataset = dataset / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a final model. I am writing this to make proper data shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 3 is input channel because of RGB * 5 images. \n",
    "        # 128 is the output channel or learnable filters\n",
    "        # Kernel size 15 is temporal kernel width (3 RGB channel * 5 images)\n",
    "        # (1*1) is spatial kernel width\n",
    "        self.conv3d = nn.Conv3d(15, 128, kernel_size=(15, 1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3d(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to make 128 size chunks of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "data = TensorDataset(dataset)\n",
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(data, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Conv3D the input format is (batch_size, num_channels, num_frames, height, width)\n",
    "So I am using unsqueeze to increase the outer dimension to make batch_size = 1 . \n",
    "\n",
    "Then using the permute to make the dimension in proper shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 114, 128, 128])\n",
      "torch.Size([1, 128, 114, 128, 128])\n",
      "torch.Size([1, 128, 19, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dataloader in batches\n",
    "for framechunk in dataloader:\n",
    "    # Access the batched tensor data\n",
    "    # Pass the input through the model\n",
    "    # print(batch[0].unsqueeze(0).size())\n",
    "    output = model(framechunk[0].unsqueeze(0).permute(0, 2, 1, 3, 4) )\n",
    "\n",
    "    print(output.shape)  # Shape of the output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
