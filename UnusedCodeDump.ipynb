{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(filenames)\n",
    "dataset = torch.zeros(dataset_size - 4, 15, 128, 128)\n",
    "for i in range(dataset_size-4):\n",
    " t_minus_2 = torchvision.io.read_image(os.path.join(data_dir, filenames[i]))\n",
    " t_minus_1 = torchvision.io.read_image(os.path.join(data_dir, filenames[i+1]))\n",
    " t = torchvision.io.read_image(os.path.join(data_dir, filenames[i+2]))\n",
    " t_plus_1 = torchvision.io.read_image(os.path.join(data_dir, filenames[i+3]))\n",
    " t_plus_2 = torchvision.io.read_image(os.path.join(data_dir, filenames[i+4]))\n",
    "\n",
    " dataset[i] = torch.cat((t_minus_2, t_minus_1, t ,t_plus_1, t_plus_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 3 is input channel because of RGB * 5 images. \n",
    "        # 128 is the output channel or learnable filters\n",
    "        # Kernel size 15 is temporal kernel width (3 RGB channel * 5 images)\n",
    "        # (1*1) is spatial kernel width\n",
    "        self.conv3d = nn.Conv3d(15, 128, kernel_size=(1, 1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3d(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal3DConv = Temporal3DConv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Conv3D the input format is (batch_size, num_channels, num_frames, height, width)\n",
    "So I am using unsqueeze to increase the outer dimension to make batch_size = 1 . \n",
    "\n",
    "Then using the permute to make the dimension in proper shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataloader in batches\n",
    "output = any\n",
    "for framechunk in dataloader:\n",
    "    # Access the batched tensor data\n",
    "    # Pass the input through the model\n",
    "    print(\">>>\",framechunk[0].unsqueeze(0).size())\n",
    "    output = temporal3DConv(framechunk[0].unsqueeze(0).permute(0, 2, 1, 3, 4) )\n",
    "\n",
    "    print(output.shape)  # Shape of the output tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a sample code to check if the design checks out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.size())\n",
    "# To match the expected input shape of the ResNet model, we need to reshape the output tensor. \n",
    "# First, we use permute to rearrange the dimensions of the tensor, swapping the second and third dimensions. \n",
    "# Then, we use contiguous to ensure the tensor's memory is laid out contiguously. \n",
    "# Finally, we use view to reshape the tensor into a 4D tensor with dimensions (batch_size * num_frames, num_channels, height, width).\n",
    "xx = output.permute(0, 2, 1, 3, 4).contiguous().view(1 * no_of_frames, 128, 128, 128)\n",
    "print(xx.size())\n",
    "layer = ResNetBlocksWithPooling(128, 64)\n",
    "layer2 = ResNetBlocksWithPooling(64, 64)\n",
    "layer3 = ResNetBlocksWithPooling(64, 64)\n",
    "flattenLayer = nn.Flatten()\n",
    "f = layer.forward(xx)\n",
    "f2 = layer2.forward(f)\n",
    "f3 = layer3.forward(f2)\n",
    "f4 = flattenLayer(f3)\n",
    "print(f.size())\n",
    "print(f2.size())\n",
    "print(f3.size())\n",
    "print(f4.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy code to check model compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of the model\n",
    "model = ActionPredictionModel(num_actions=4)\n",
    "\n",
    "output = model(f4)\n",
    "print(output)  # Output shape: (128, 4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
