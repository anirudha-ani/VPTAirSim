{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(filenames)\n",
    "dataset = torch.zeros(dataset_size - 4, 15, 128, 128)\n",
    "for i in range(dataset_size-4):\n",
    " t_minus_2 = torchvision.io.read_image(os.path.join(data_dir, filenames[i]))\n",
    " t_minus_1 = torchvision.io.read_image(os.path.join(data_dir, filenames[i+1]))\n",
    " t = torchvision.io.read_image(os.path.join(data_dir, filenames[i+2]))\n",
    " t_plus_1 = torchvision.io.read_image(os.path.join(data_dir, filenames[i+3]))\n",
    " t_plus_2 = torchvision.io.read_image(os.path.join(data_dir, filenames[i+4]))\n",
    "\n",
    " dataset[i] = torch.cat((t_minus_2, t_minus_1, t ,t_plus_1, t_plus_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 3 is input channel because of RGB * 5 images. \n",
    "        # 128 is the output channel or learnable filters\n",
    "        # Kernel size 15 is temporal kernel width (3 RGB channel * 5 images)\n",
    "        # (1*1) is spatial kernel width\n",
    "        self.conv3d = nn.Conv3d(15, 128, kernel_size=(1, 1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3d(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
